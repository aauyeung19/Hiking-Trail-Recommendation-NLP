{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Trail Reviews Visualization Notebook \n",
    "Author: Andrew Auyeung. \n",
    "The contents of this notebook are the visualizations done after the Trail Reviews are cleaned and have undergone some form of topic modeling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import nlp_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../src/cleaned_reviews_5.csv\", index_col=0)\n",
    "reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000, max_df=0.7, min_df=0.01, ngram_range=(1,2), stop_words='english')\n",
    "r_dtm = vectorizer.fit_transform(reviews['cleaned_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=10, random_state=None)\n",
    "nmf_model.fit(r_dtm)\n",
    "\n",
    "nlp_vis.display_topics(model=nmf_model, feature_names=vectorizer.get_feature_names(), no_top_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = []\n",
    "words = vectorizer.get_feature_names()\n",
    "for topic in nmf_model.components_.argsort()[:,:-4:-1]:\n",
    "    curr_names = []\n",
    "    for i in topic:\n",
    "        curr_names.append(words[i])\n",
    "    topic_names.append(' ,'.join(curr_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(r_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(topic_results, index=reviews.index, columns=topic_names)\n",
    "\n",
    "y = topic_results.argmax(axis=1)\n"
   ]
  },
  {
   "source": [
    "# Visualization of NMF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## PCA Vis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_features = pca.fit_transform(X)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_vis.plot_PCA_2D(pca_features, y, X.columns)"
   ]
  },
  {
   "source": [
    "## t-SNE Vis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, n_iter=300)\n",
    "t_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_vis.plot_tSNE_2D(t_results, y, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_level_2 = TruncatedSVD(n_components=6)\n",
    "lsa_level_2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results_level2 = lsa_level_2.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Topic Clusters\n",
    "topic_clusters = []\n",
    "for cluster in lsa_level_2.components_.argsort()[:,:-4:-1]:\n",
    "    curr_names = []\n",
    "    for i in cluster:\n",
    "        curr_names.append(topic_names[i])\n",
    "    topic_clusters.append(' ,'.join(curr_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_clusters"
   ]
  },
  {
   "source": [
    "# CorEx Topic Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "import re\n",
    "import scipy.sparse as ss\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.8, min_df=0.01, ngram_range=(1,2))\n",
    "r_dtm = vectorizer.fit_transform(reviews['cleaned_reviews'])\n",
    "words = list(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Topic Model\n",
    "topic_model = ct.Corex(n_hidden=20, words=words, verbose=False)\n",
    "topic_model.fit(r_dtm, words=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_CorEx_topics(model):\n",
    "    \"\"\"\n",
    "    Shows the words associated with the topics in a CoRex Model\n",
    "    If not anchored, the topic correlation will be sorted in descending order\n",
    "    \"\"\"\n",
    "    topics = model.get_topics()\n",
    "    for n, topic in enumerate(topics):\n",
    "        topic_words, _ = zip(*topic) \n",
    "        print(f'Topic {n}: TC Score:{model.tcs[n]}: \\n', ', '.join(topic_words))\n",
    "# nlp_vis.show_CorEx_topics(topic_model)\n",
    "show_CorEx_topics(topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names_corex = []\n",
    "for topic in topic_model.get_topics():\n",
    "    words, _ = zip(*topic)\n",
    "    curr_names = []\n",
    "    for i in words[:3]:\n",
    "        curr_names.append(i)\n",
    "    topic_names_corex.append(', '.join(curr_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names_corex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color='#4e79a7', width=0.5)\n",
    "plt.xlabel('Topic', fontsize=16)\n",
    "plt.ylabel('Total Correlation (nats)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Drop off in correlation around 4 clusters and again at 8 clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Try 8 Topics CorEx"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Topic Model\n",
    "topic_model = ct.Corex(n_hidden=8, words=words, verbose=False)\n",
    "topic_model.fit(r_dtm, words=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names_corex = []\n",
    "for topic in topic_model.get_topics():\n",
    "    words, _ = zip(*topic)\n",
    "    curr_names = []\n",
    "    for i in words[:3]:\n",
    "        curr_names.append(i)\n",
    "    topic_names_corex.append(', '.join(curr_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_CorEx_topics(topic_model)\n",
    "# Topic Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corex = pd.DataFrame(topic_model.p_y_given_x, index=reviews.index, columns=topic_names_corex)\n",
    "y = topic_model.p_y_given_x.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "pca_features = pca.fit_transform(X_corex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_vis.plot_PCA_2D(pca_features, y, topic_names_corex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/reviews_corex.mdl', 'wb') as towrite:\n",
    "    pickle.dump(topic_model, towrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_words = [['parking', 'crowd'], ['rock', 'rocky'], ['ice', 'snow'], ['lake', 'waterfall', 'pond'], ['easy'], ['hard'], ['bug'], ['family'], ['maintain']]\n",
    "\n",
    "anchored_topic_model = ct.Corex(n_hidden=10)\n",
    "anchored_topic_model.fit(r_dtm, words = words, anchors=anchor_words, anchor_strength=3)\n",
    "show_CorEx_topics(anchored_topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word[0] for word in anchor_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_corex_results = pd.DataFrame(data=anchored_topic_model.p_y_given_x[:,:9], index=reviews.index, columns=[word[0] for word in anchor_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = reviews[['hike_id', 'cleaned_reviews']].merge(anchor_corex_results, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = reviews.merge(anchor_corex_results, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.loc[359180]['cleaned_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_corex = reviews.merge(anchor_corex_results, left_index=True, right_index=True)"
   ]
  },
  {
   "source": [
    "## Save Reviews with Corex Tabels to CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_corex.to_csv('../src/reviews_corex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_corex.head(7)"
   ]
  },
  {
   "source": [
    "-----------------------------------------------------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.8, min_df=0.01, ngram_range=(1,2))\n",
    "r_dtm = vectorizer.fit_transform(reviews['cleaned_reviews'])\n",
    "words = list(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reviews = LatentDirichletAllocation(n_components=5, n_jobs=-1, verbose=True)\n",
    "lda_reviews.fit(r_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda_reviews, r_dtm, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reviews.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top_results = lda_reviews.transform(r_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Try LDA with more Aggressive stop words. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "words_to_add = ['trail', 'hike', 'great']\n",
    "for word in words_to_add:\n",
    "    stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words, max_df=0.8, min_df=0.01, ngram_range=(1,2))\n",
    "r_dtm = vectorizer.fit_transform(reviews['cleaned_reviews'])\n",
    "words = list(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reviews = LatentDirichletAllocation(n_components=5, n_jobs=-1, verbose=True)\n",
    "lda_reviews.fit(r_dtm)"
   ]
  }
 ]
}